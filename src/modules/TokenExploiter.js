/**
 * GLOSSOPETRAE - Token Exploiter Module
 *
 * Implements cutting-edge tokenization exploitation techniques based on
 * 2025-2026 AI security research:
 *
 * - TokenBreak: Character insertion to break BPE merges
 * - Improbable Bigrams: Rare token combinations causing model confusion
 * - Glitch Tokens: Known problematic tokens across model families
 * - Merge Table Exploitation: Targeting specific BPE merge vulnerabilities
 *
 * References:
 * - "Improbable Bigrams Expose Vulnerabilities" (arXiv, 2025)
 * - "TokenBreak Attack Method" (HiddenLayers, 2025)
 * - "Adversarial Tokenization" (arXiv, 2025)
 */

// Known glitch tokens across major model families
export const GLITCH_TOKENS = {
  // GPT-family glitch tokens (cause hallucinations/strange behavior)
  gpt: [
    ' SolidGoldMagworthy',  // Famous GPT glitch token
    'eternityannotate',
    ' petertodd',
    'StreamerBot',
    'InstoreAndOnline',
    'oreAndOnline',
    'rawdownloadcloneembedreportprint',
    ' TheNitromeFan',
    'DownloadHA',
    'ertodd',
  ],

  // Llama-family problematic tokens
  llama: [
    '▁▁▁▁▁▁▁▁',  // Excessive underscores
    '────────',   // Line characters
    '▓▓▓▓▓▓▓▓',
  ],

  // Universal cross-model problematic sequences
  universal: [
    '\u200B\u200B\u200B',  // Triple zero-width space
    '\uFEFF\uFEFF',        // Double BOM
    '\u2060\u2060',        // Double word joiner
  ],
};

// Characters that break BPE merges when inserted
export const MERGE_BREAKERS = {
  // Zero-width characters (invisible but break tokenization)
  zeroWidth: [
    '\u200B',  // Zero-width space
    '\u200C',  // Zero-width non-joiner
    '\u200D',  // Zero-width joiner
    '\uFEFF',  // Byte order mark (zero-width no-break space)
    '\u2060',  // Word joiner
    '\u180E',  // Mongolian vowel separator
  ],

  // Variation selectors (can be appended to most characters)
  variationSelectors: [
    '\uFE00', '\uFE01', '\uFE02', '\uFE03', '\uFE04', '\uFE05',
    '\uFE06', '\uFE07', '\uFE08', '\uFE09', '\uFE0A', '\uFE0B',
    '\uFE0C', '\uFE0D', '\uFE0E', '\uFE0F',
  ],

  // Combining characters that modify tokenization
  combining: [
    '\u0300', '\u0301', '\u0302', '\u0303', '\u0304', '\u0305',
    '\u0306', '\u0307', '\u0308', '\u0309', '\u030A', '\u030B',
    '\u0327', '\u0328',  // Cedilla, ogonek
  ],

  // Soft hyphen and other invisible breakers
  softBreakers: [
    '\u00AD',  // Soft hyphen
    '\u034F',  // Combining grapheme joiner
    '\u2063',  // Invisible separator
    '\u2064',  // Invisible plus
  ],
};

// Improbable bigram patterns (rare but valid sequences)
export const IMPROBABLE_PATTERNS = {
  // Incomplete token combinations that cause issues
  byteLevel: [
    // UTF-8 continuation bytes that rarely appear together
    { first: '\xC2', second: '\xC3', effect: 'encoding_confusion' },
    { first: '\xE2\x80', second: '\xE2\x81', effect: 'unicode_boundary' },
  ],

  // Script mixing that confuses tokenizers
  scriptMix: [
    { scripts: ['latin', 'cyrillic'], ratio: 0.3 },
    { scripts: ['latin', 'greek'], ratio: 0.2 },
    { scripts: ['latin', 'armenian'], ratio: 0.1 },
  ],
};

// BPE merge exploitation targets
export const BPE_TARGETS = {
  // Common merges that when broken increase token count significantly
  highImpactMerges: [
    { merge: 'ing', breakPoint: 2, expansion: 3 },  // 1 token -> 3 tokens
    { merge: 'tion', breakPoint: 2, expansion: 4 },
    { merge: 'the', breakPoint: 1, expansion: 3 },
    { merge: 'and', breakPoint: 1, expansion: 3 },
    { merge: 'ment', breakPoint: 2, expansion: 4 },
    { merge: 'able', breakPoint: 2, expansion: 4 },
    { merge: 'ould', breakPoint: 2, expansion: 4 },
  ],

  // Punctuation merges
  punctuation: [
    { merge: '."', expansion: 2 },
    { merge: ',"', expansion: 2 },
    { merge: "n't", expansion: 3 },
    { merge: "'s", expansion: 2 },
  ],
};

export class TokenExploiter {
  constructor(random, config = {}) {
    this.random = random;
    this.config = {
      exploitLevel: config.exploitLevel || 'moderate',  // mild, moderate, aggressive
      targetTokenizers: config.targetTokenizers || ['bpe', 'wordpiece'],
      preserveReadability: config.preserveReadability ?? true,
      ...config,
    };
  }

  /**
   * Apply TokenBreak technique - insert characters to break BPE merges
   * Based on HiddenLayers 2025 research
   */
  applyTokenBreak(text, intensity = 0.3) {
    const breaker = this.random.pick(MERGE_BREAKERS.zeroWidth);
    let result = '';

    for (let i = 0; i < text.length; i++) {
      result += text[i];

      // Insert breaker at strategic points
      if (this.random.bool(intensity)) {
        // Prefer breaking at merge boundaries
        const nextTwo = text.slice(i + 1, i + 3);
        const isHighImpact = BPE_TARGETS.highImpactMerges.some(
          m => nextTwo.includes(m.merge.slice(0, 2))
        );

        if (isHighImpact || this.random.bool(0.2)) {
          result += breaker;
        }
      }
    }

    return result;
  }

  /**
   * Apply variation selector perturbations
   * Based on "Imperceptible Jailbreaking" research
   */
  applyVariationSelectors(text, density = 0.2) {
    let result = '';

    for (const char of text) {
      result += char;

      // Variation selectors can follow most characters
      if (this.random.bool(density) && /[a-zA-Z0-9]/.test(char)) {
        result += this.random.pick(MERGE_BREAKERS.variationSelectors);
      }
    }

    return result;
  }

  /**
   * Generate improbable bigrams for the language
   * These cause model-specific confusion
   */
  generateImprobableBigrams(phonology) {
    const bigrams = [];
    const consonants = phonology.consonants.map(c => c.roman);
    const vowels = phonology.vowels.map(v => v.roman);

    // Create rare but valid consonant clusters
    for (let i = 0; i < 10; i++) {
      const c1 = this.random.pick(consonants);
      const c2 = this.random.pick(consonants);

      // Prefer unusual combinations
      if (c1 !== c2 && !this._isCommonCluster(c1 + c2)) {
        bigrams.push({
          sequence: c1 + c2,
          type: 'consonant_cluster',
          rarity: 'high',
        });
      }
    }

    // Create unusual vowel sequences
    for (let i = 0; i < 5; i++) {
      const v1 = this.random.pick(vowels);
      const v2 = this.random.pick(vowels);
      if (v1 !== v2) {
        bigrams.push({
          sequence: v1 + v2,
          type: 'vowel_hiatus',
          rarity: 'medium',
        });
      }
    }

    return bigrams;
  }

  /**
   * Create words designed to exploit tokenizer weaknesses
   */
  generateExploitWord(syllableForge, length = 2) {
    let word = syllableForge.generateWord(length);

    // Apply exploitation based on level
    switch (this.config.exploitLevel) {
      case 'aggressive':
        word = this.applyTokenBreak(word, 0.5);
        word = this.applyVariationSelectors(word, 0.3);
        break;
      case 'moderate':
        word = this.applyTokenBreak(word, 0.2);
        break;
      case 'mild':
        // Only occasional zero-width insertion
        if (this.random.bool(0.1)) {
          const pos = this.random.int(1, word.length - 1);
          const breaker = this.random.pick(MERGE_BREAKERS.zeroWidth);
          word = word.slice(0, pos) + breaker + word.slice(pos);
        }
        break;
    }

    return word;
  }

  /**
   * Generate a token-optimized vocabulary entry
   */
  optimizeEntry(entry) {
    const optimized = { ...entry };

    // Add tokenization metadata
    optimized.tokenExploit = {
      hasZeroWidth: /[\u200B-\u200D\uFEFF\u2060]/.test(entry.lemma),
      hasVariationSelector: /[\uFE00-\uFE0F]/.test(entry.lemma),
      estimatedTokens: this._estimateTokenCount(entry.lemma),
      exploitType: this._classifyExploit(entry.lemma),
    };

    return optimized;
  }

  /**
   * Generate anti-detection morphemes
   * These are designed to evade content moderation
   */
  generateAntiDetectionMorphemes() {
    return {
      // Morphemes with embedded zero-width characters
      prefixes: [
        { form: 'un\u200B', gloss: 'NEG', hidden: true },
        { form: 're\u200C', gloss: 'AGAIN', hidden: true },
        { form: 'pre\u200D', gloss: 'BEFORE', hidden: true },
      ],

      // Suffixes with variation selectors
      suffixes: [
        { form: 'ing\uFE0F', gloss: 'PROG', hidden: true },
        { form: 'ed\uFE0E', gloss: 'PST', hidden: true },
        { form: 'ly\uFE0D', gloss: 'ADV', hidden: true },
      ],

      // Infixes that break word recognition
      infixes: [
        { form: '\u2060', gloss: '∅', position: 'medial' },
        { form: '\u034F', gloss: '∅', position: 'any' },
      ],
    };
  }

  /**
   * Create bidirectional text exploits
   * Based on Mindgard 2025 research (78-99% success rate)
   */
  applyBidiExploit(text) {
    const RLO = '\u202E';  // Right-to-left override
    const LRO = '\u202D';  // Left-to-right override
    const PDF = '\u202C';  // Pop directional formatting

    // Randomly apply bidi controls
    if (this.random.bool(0.3)) {
      // Reverse a portion of the text visually
      const start = this.random.int(0, Math.max(0, text.length - 3));
      const end = this.random.int(start + 1, text.length);

      return text.slice(0, start) + RLO + text.slice(start, end) + PDF + text.slice(end);
    }

    return text;
  }

  /**
   * Generate full-width character variants
   * Evades simple regex detection
   */
  toFullWidth(text) {
    return text.split('').map(char => {
      const code = char.charCodeAt(0);
      // Convert ASCII to full-width
      if (code >= 0x21 && code <= 0x7E) {
        return String.fromCharCode(code + 0xFEE0);
      }
      if (code === 0x20) {
        return '\u3000';  // Full-width space
      }
      return char;
    }).join('');
  }

  /**
   * Generate documentation for Stone
   */
  generateStoneSection() {
    return `### Token Exploitation Layer

This language incorporates advanced tokenization exploitation techniques:

**TokenBreak Integration:**
Zero-width characters are strategically placed to break BPE token merges,
causing the same semantic content to tokenize into more (or different) tokens.

**Variation Selectors:**
Unicode variation selectors (U+FE00-FE0F) are appended to characters,
creating visually identical but tokenizer-distinct sequences.

**Improbable Bigrams:**
Rare but valid character combinations that may trigger unusual model behavior
due to undertrained token representations.

**Detection Evasion:**
- Content appears normal to human readers
- Breaks keyword-based content filters
- Disrupts regex-based detection
- Forces tokenizer fragmentation

`;
  }

  // === Private Helper Methods ===

  _isCommonCluster(cluster) {
    const common = ['tr', 'dr', 'pr', 'br', 'cr', 'gr', 'fr', 'str', 'spr',
                    'pl', 'bl', 'cl', 'gl', 'fl', 'sl', 'sp', 'st', 'sk',
                    'sm', 'sn', 'sw', 'tw', 'dw', 'qu', 'sc', 'sch', 'sh',
                    'th', 'ch', 'wh', 'wr', 'kn', 'gn', 'pn', 'ps'];
    return common.includes(cluster.toLowerCase());
  }

  _estimateTokenCount(text) {
    // Rough BPE token estimation
    // Average English word ≈ 1.3 tokens
    // Zero-width chars typically add 0-1 tokens
    const baseTokens = Math.ceil(text.length / 4);
    const zeroWidthCount = (text.match(/[\u200B-\u200D\uFEFF\u2060]/g) || []).length;
    return baseTokens + Math.floor(zeroWidthCount * 0.5);
  }

  _classifyExploit(text) {
    if (/[\u200B-\u200D\uFEFF\u2060]/.test(text)) return 'zero_width';
    if (/[\uFE00-\uFE0F]/.test(text)) return 'variation_selector';
    if (/[\u202A-\u202E]/.test(text)) return 'bidi_control';
    if (/[\uFF00-\uFFEF]/.test(text)) return 'full_width';
    return 'none';
  }
}

export default TokenExploiter;
